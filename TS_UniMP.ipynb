{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  赛题链接：[常规赛：图神经网络入门节点分类](https://aistudio.baidu.com/aistudio/competition/detail/59)\n",
    "\n",
    "## （1）赛题介绍\n",
    "图神经网络（Graph Neural Network）是一种专门处理图结构数据的神经网络，目前被广泛应用于推荐系统、金融风控、生物计算中。图神经网络的经典问题主要有三种，包括节点分类、连接预测和图分类三种。本次比赛是图神经网络7日打卡课程的大作业，主要让同学们熟悉如何图神经网络处理节点分类问题。\n",
    "\n",
    "在过去的一个世纪里，科学出版物的数量每12年增加近一倍，对每一种出版物的主题及领域进行自动分类已成为当下十分重要的工作。本次任务的目标是预测未知论文的主题类别，如软件工程，人工智能，语言计算和操作系统等。比赛所选35个领域标签已得到论文作者和arXiv版主确认并标记。\n",
    "\n",
    "本次比赛选用的数据集为arXiv论文引用网络——ogbn-arixv数据集的子集。ogbn-arixv数据集由大量的学术论文组成，论文之间的引用关系形成一张巨大的有向图，每一条有向边表示一篇论文引用另一篇论文，每一个节点提供100维简单的词向量作为节点特征。在论文引用网络中，我们已对训练集对应节点做了论文类别标注处理。本次任务希望参赛者通过已有的节点类别以及论文之间的引用关系，预测未知节点的论文类别。\n",
    "\n",
    "## （2）数据描述\n",
    "本次赛题数据集由学术网络图构成，该图会给出每个节点的特征，以及节点与节点间关系（训练集节点的标注结果已给出）。\n",
    "\n",
    "### 数据集简介：\n",
    "**1.学术网络图数据：**\n",
    "\n",
    "该图包含1647958条有向边，130644个节点，参赛者报名成功后即可通过比赛数据集页面提供edges.csv以及feat.npy下载并读取数据。图上的每个节点代表一篇论文，论文从0开始编号；图上的每一条边包含两个编号，例如 3，4代表第3篇论文引用了第4篇论文。图构造可以参照AiStudio上提供的基线系统项目了解数据读取方法。\n",
    "\n",
    "**2.训练集与测试集：**\n",
    "\n",
    "训练集的标注数据有70235条，测试集的标注数据有37311条。训练数据给定了论文编号与类别，如3，15 代表编号为3的论文类别为15。测试集数据只提供论文编号，不提供论文类别，需要参赛者预测其类别。\n",
    "\n",
    "具体数据介绍：\n",
    "\n",
    "**1.图数据：**\n",
    "\n",
    "feat.npy为Numpy格式存储的节点特征矩阵，Shape为(130644, 100)，即130644个节点，每个节点含100维特征。其中 feat.npy可以用numpy.load(“feat.npy”)读取。edges.csv用于标记论文引用关系，为无向图，且由两列组成，没有表头。\n",
    "| 字段 | 说明 |\n",
    "| -------- | -------- |\n",
    "| 第一列 | 边的初始节点 |\n",
    "| 第二列 | 边的终止节点 |\n",
    "\n",
    "**2.训练集： train.csv**\n",
    "| 字段 | 说明 |\n",
    "| -------- | -------- |\n",
    "| nid | 训练节点在图上的Id |\n",
    "| label | 训练节点的标签（类别编号从0开始，共35个类别） |\n",
    "\n",
    "**3.测试集： test.csv**\n",
    "| 字段 | 说明 |\n",
    "| -------- | -------- |\n",
    "| nid | 测试节点在图上的Id |\n",
    "\n",
    "## （3）代码参考及改动\n",
    "代码主要是根据怀瑾大大的比赛经验和心得进行了微小改动。本次主要是将传统的UniMP改动成为一种双流UniMP模型，即包含两个分支，一个分支的use_label属性被设置为False，另一个为True（但是并没有针对改动的有效性进行验证，貌似和原始版本效果差不多，觉得主要还是调参的贡献比较大，UniMP效果真的是牛）（PS:checkpoints忘保存了，被后面的结果给覆盖了）。\n",
    "\n",
    "（1） [常规赛：论文引用网络节点分类比赛经验及心得](https://aistudio.baidu.com/aistudio/projectdetail/1921004?channelType=0&channel=0)\n",
    "\n",
    "\n",
    "## （4）提交内容与格式\n",
    "\n",
    "最终提交的submission.csv 格式如下：\n",
    "| 字段 | 说明 |\n",
    "| -------- | -------- |\n",
    "| nid | 测试集节点在图上的id |\n",
    "| label | 测试集的节点类别 |\n",
    "\n",
    "**特别提示：** 提交的结果必须是类别的id，不能是概率。\n",
    "\n",
    "提交样例：\n",
    "| nid | label |\n",
    "| -------- | -------- |\n",
    "| 2 | 34 |\n",
    "| 3 | 1 |\n",
    "| 4 | 15 |\n",
    "| … | … |\n",
    "\n",
    "\n",
    "**注意**：选手提交的csv文件的第一行为”nid,label”，顺序调转将视为无效答案。接下来每一行的两个数字依次表示测试集提供的节点id以及对应的预测论文类别，注意给出的预测类别id要属于给定范围值且必须是整数。提交的数据行数要与test.csv一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行方式\n",
    "本次基线基于飞桨PaddlePaddle 1.8.4版本，若本地运行则可能需要额外安装pgl、easydict、pandas等模块。\n",
    "\n",
    "## 1.本地运行\n",
    "下载左侧文件夹中的所有py文件（包括build_model.py, model.py）,以及work目录，然后在右上角“文件”->“导出Notebook到py”，这样可以保证代码是最新版本），执行导出的py文件即可。完成后下载submission.csv提交结果即可。\n",
    "\n",
    "## 2.AI Studio (Notebook)运行\n",
    "依次运行下方的cell，完成后下载submission.csv提交结果即可。**若运行时修改了cell，推荐在右上角重启执行器后再以此运行，避免因内存未清空而产生报错**。 Tips：若修改了左侧文件夹中数据，也需要重启执行器后才会加载新文件。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码整体逻辑\n",
    "\n",
    "1. 读取提供的数据集，包含构图以及读取节点特征（用户可自己改动边的构造方式）\n",
    "\n",
    "2. 配置化生成模型，用户也可以根据教程进行图神经网络的实现。\n",
    "\n",
    "3. 开始训练\n",
    "\n",
    "4. 执行预测并产生结果文件\n",
    "\n",
    "## （1）环境配置\n",
    "\n",
    "该项目依赖飞桨paddlepaddle==1.8.4, 以及pgl==1.2.0。请按照版本号下载对应版本就可运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-18T01:26:46.292147Z",
     "iopub.status.busy": "2021-12-18T01:26:46.291619Z",
     "iopub.status.idle": "2021-12-18T01:27:09.122879Z",
     "shell.execute_reply": "2021-12-18T01:27:09.121852Z",
     "shell.execute_reply.started": "2021-12-18T01:26:46.292117Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: 无法创建目录\"/home/aistudio/external-libraries\": 文件已存在\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Requirement already satisfied: pgl==1.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: redis-py-cluster in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl==1.2.0) (2.1.3)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl==1.2.0) (1.16.4)\n",
      "Requirement already satisfied: visualdl>=2.0.0b; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl==1.2.0) (2.2.0)\n",
      "Requirement already satisfied: cython>=0.25.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl==1.2.0) (0.29)\n",
      "Requirement already satisfied: redis<4.0.0,>=3.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from redis-py-cluster->pgl==1.2.0) (3.5.3)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.8.53)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (3.14.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.22.0)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (3.8.2)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.7.1.1)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (7.1.2)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.0.0)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.21.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.1.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.2.3)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.1.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.15.0)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.18.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (3.9.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2019.9.11)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.2.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.23)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.6.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.6.1)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2019.3)\n",
      "Requirement already satisfied: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.11.0)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.3.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.0.1)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (16.7.9)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (5.1.2)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.3.4)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.4.10)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.10.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (41.4.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting xgboost==1.1.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/75/6c/fb30ff1703846db8e8e511399e41123ac968dc29171f04e9f0b2585e40c9/xgboost-1.1.0-py3-none-manylinux2010_x86_64.whl\n",
      "Collecting easydict\n",
      "Collecting scipy (from xgboost==1.1.0)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/58/4f/11f34cfc57ead25752a7992b069c36f5d18421958ebd6466ecd849aeaf86/scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting numpy (from xgboost==1.1.0)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/5b/0d/de55834c5ea0dd287cb1cb156c8bc120af2863c36e4d49b4dc28f174e278/numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "\u001b[31mERROR: blackhole 1.0.1 has requirement numpy<=1.19.5, but you'll have numpy 1.21.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, scipy, xgboost, easydict\n",
      "Successfully installed easydict-1.9 numpy-1.21.4 scipy-1.7.3 xgboost-1.1.0\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/easydict already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/easydict-1.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/numpy-1.21.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/xgboost-1.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/scipy-1.7.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/xgboost already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "!mkdir /home/aistudio/external-libraries\n",
    "\n",
    "!pip install pgl==1.2.0 -i https://mirror.baidu.com/pypi/simple\n",
    "!pip install xgboost==1.1.0 easydict -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-18T01:27:09.124826Z",
     "iopub.status.busy": "2021-12-18T01:27:09.124453Z",
     "iopub.status.idle": "2021-12-18T01:27:09.129228Z",
     "shell.execute_reply": "2021-12-18T01:27:09.128553Z",
     "shell.execute_reply.started": "2021-12-18T01:27:09.124795Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-18T01:27:09.130770Z",
     "iopub.status.busy": "2021-12-18T01:27:09.130193Z",
     "iopub.status.idle": "2021-12-18T01:27:10.666054Z",
     "shell.execute_reply": "2021-12-18T01:27:10.665130Z",
     "shell.execute_reply.started": "2021-12-18T01:27:09.130738Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pgl\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （2）图网络配置\n",
    "\n",
    "这里已经有很多强大的模型配置，你可以尝试简单的改一下config的字段。\n",
    "例如，换成GAT的配置：\n",
    "```\n",
    "config = {\n",
    "    \"model_name\": \"GAT\",\n",
    "    \"num_layers\":  1,\n",
    "    \"dropout\": 0.5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"edge_dropout\": 0.00,\n",
    "}\n",
    "```\n",
    "下面采用了双流UniMP的配置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-18T01:27:10.667921Z",
     "iopub.status.busy": "2021-12-18T01:27:10.667446Z",
     "iopub.status.idle": "2021-12-18T01:27:10.673521Z",
     "shell.execute_reply": "2021-12-18T01:27:10.672904Z",
     "shell.execute_reply.started": "2021-12-18T01:27:10.667888Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "\n",
    "config = {\n",
    "    \"model_name\": \"TS_UniMP\",\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 32,\n",
    "    \"heads\": 8,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"dropout\": 0.4,\n",
    "    \"weight_decay\": 0.0003,\n",
    "    \"edge_dropout\": 0.3,\n",
    "    \"use_label_e\": True\n",
    "}\n",
    "\n",
    "\n",
    "config = edict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （3）数据加载模块\n",
    "\n",
    "这里主要是用于读取数据集，包括读取图数据构图，以及训练集的划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-18T01:27:10.675803Z",
     "iopub.status.busy": "2021-12-18T01:27:10.675572Z",
     "iopub.status.idle": "2021-12-18T01:27:10.687707Z",
     "shell.execute_reply": "2021-12-18T01:27:10.687047Z",
     "shell.execute_reply.started": "2021-12-18T01:27:10.675777Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Dataset = namedtuple(\"Dataset\", \n",
    "               [\"graph\", \"num_classes\", \"train_index\",\n",
    "                \"train_label\", \"valid_index\", \"valid_label\", \"test_index\"])\n",
    "\n",
    "def load_edges(num_nodes, self_loop=True, add_inverse_edge=True):\n",
    "    # 从数据中读取边\n",
    "    edges = pd.read_csv(\"work/edges.csv\", header=None, names=[\"src\", \"dst\"]).values\n",
    "\n",
    "    if add_inverse_edge:\n",
    "        edges = np.vstack([edges, edges[:, ::-1]])\n",
    "\n",
    "    if self_loop:\n",
    "        src = np.arange(0, num_nodes)\n",
    "        dst = np.arange(0, num_nodes)\n",
    "        self_loop = np.vstack([src, dst]).T\n",
    "        edges = np.vstack([edges, self_loop])\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def load():\n",
    "    # 从数据中读取点特征和边，以及数据划分\n",
    "    node_feat = np.load(\"work/feat.npy\")\n",
    "    num_nodes = node_feat.shape[0]\n",
    "    edges = load_edges(num_nodes=num_nodes, self_loop=True, add_inverse_edge=True)\n",
    "    graph = pgl.graph.Graph(num_nodes=num_nodes, edges=edges, node_feat={\"feat\": node_feat})\n",
    "    \n",
    "    indegree = graph.indegree()\n",
    "    norm = np.maximum(indegree.astype(\"float32\"), 1)\n",
    "    norm = np.power(norm, -0.5)\n",
    "    graph.node_feat[\"norm\"] = np.expand_dims(norm, -1)\n",
    "    \n",
    "    df = pd.read_csv(\"work/train.csv\")\n",
    "    node_index = df[\"nid\"].values\n",
    "    node_label = df[\"label\"].values\n",
    "    #调整好超参数后可以增大训练集的比例\n",
    "    train_part = int(len(node_index) * 0.9)\n",
    "    train_index = node_index[:train_part]\n",
    "    train_label = node_label[:train_part]\n",
    "    valid_index = node_index[train_part:]\n",
    "    valid_label = node_label[train_part:]\n",
    "    test_index = pd.read_csv(\"work/test.csv\")[\"nid\"].values\n",
    "    dataset = Dataset(graph=graph, \n",
    "                    train_label=train_label,\n",
    "                    train_index=train_index,\n",
    "                    valid_index=valid_index,\n",
    "                    valid_label=valid_label,\n",
    "                    test_index=test_index, num_classes=35)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-18T01:27:10.688788Z",
     "iopub.status.busy": "2021-12-18T01:27:10.688592Z",
     "iopub.status.idle": "2021-12-18T01:27:11.145869Z",
     "shell.execute_reply": "2021-12-18T01:27:11.145052Z",
     "shell.execute_reply.started": "2021-12-18T01:27:10.688764Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = load()\n",
    "\n",
    "train_index = dataset.train_index\n",
    "train_label = np.reshape(dataset.train_label, [-1 , 1])\n",
    "train_index = np.expand_dims(train_index, -1)\n",
    "\n",
    "val_index = dataset.valid_index\n",
    "val_label = np.reshape(dataset.valid_label, [-1, 1])\n",
    "val_index = np.expand_dims(val_index, -1)\n",
    "\n",
    "test_index = dataset.test_index\n",
    "test_index = np.expand_dims(test_index, -1)\n",
    "test_label = np.zeros((len(test_index), 1), dtype=\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （4）组网模块\n",
    "\n",
    "这里是组网模块，目前已经提供了一些预定义的模型，包括**GCN**, **GAT**, **APPNP**等。可以通过简单的配置，设定模型的层数，hidden_size等。你也可以深入到model.py里面，去奇思妙想，写自己的图神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-18T01:27:11.147364Z",
     "iopub.status.busy": "2021-12-18T01:27:11.147122Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pgl\n",
    "import model\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "import time\n",
    "from build_model import build_model\n",
    "\n",
    "# 使用CPU\n",
    "#place = fluid.CPUPlace()\n",
    "\n",
    "# # 使用GPU\n",
    "place = fluid.CUDAPlace(0)\n",
    "\n",
    "train_program = fluid.default_main_program()\n",
    "startup_program = fluid.default_startup_program()\n",
    "with fluid.program_guard(train_program, startup_program):\n",
    "    with fluid.unique_name.guard():\n",
    "        gw, loss, acc, pred = build_model(dataset,\n",
    "                            config=config,\n",
    "                            phase=\"train\",\n",
    "                            main_prog=train_program)\n",
    "\n",
    "test_program = fluid.Program()\n",
    "with fluid.program_guard(test_program, startup_program):\n",
    "    with fluid.unique_name.guard():\n",
    "        _gw, v_loss, v_acc, v_pred = build_model(dataset,\n",
    "            config=config,\n",
    "            phase=\"test\",\n",
    "            main_prog=test_program)\n",
    "\n",
    "\n",
    "test_program = test_program.clone(for_test=True)\n",
    "\n",
    "exe = fluid.Executor(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(feed_dict, test_index,test_label, test_program, use_label_e, train_index, train_label, epoch):\n",
    "    feed_dict[\"node_index\"] = np.array(test_index, dtype=\"int64\")\n",
    "    feed_dict[\"node_label\"] = np.array(test_label, dtype=\"int64\") #假标签\n",
    "\n",
    "    if use_label_e:\n",
    "        feed_dict['label_idx'] = np.array(train_index, dtype=\"int64\")\n",
    "        feed_dict['label'] = np.array(train_label, dtype=\"int64\")\n",
    "\n",
    "    test_prediction = exe.run(test_program,\n",
    "                                feed=feed_dict,\n",
    "                                fetch_list=[v_pred],\n",
    "                                return_numpy=True)[0]\n",
    "    submission = pd.DataFrame(data={\n",
    "                            \"nid\": test_index.reshape(-1),\n",
    "                            \"label\": test_prediction.reshape(-1)\n",
    "                        })\n",
    "    submission.to_csv(\"submission\"+str(epoch)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （5）开始训练过程\n",
    "\n",
    "图神经网络采用FullBatch的训练方式，每一步训练就会把所有整张图训练样本全部训练一遍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "use_label_e = True\n",
    "label_rate = 0.6\n",
    "epoch = 2000\n",
    "exe.run(startup_program)\n",
    "max_val_acc = 0\n",
    "\n",
    "val_acc_history = 0\n",
    "early_stop_counter = 0\n",
    "\n",
    "# 这里可以恢复训练\n",
    "pretrained = False\n",
    "if pretrained:\n",
    "    def name_filter(var):\n",
    "        res = var.name in os.listdir('./output')\n",
    "        return res\n",
    "    fluid.io.load_vars(exe, './output',predicate=name_filter)\n",
    "\n",
    "earlystop = 0\n",
    "# 将图数据变成 feed_dict 用于传入Paddle Excecutor\n",
    "feed_dict = gw.to_feed(dataset.graph)\n",
    "for epoch in range(epoch):\n",
    "    # Full Batch 训练\n",
    "    # 设定图上面那些节点要获取\n",
    "    # node_index: 训练节点的nid    \n",
    "    # node_label: 训练节点对应的标签\n",
    "    \n",
    "    if use_label_e:\n",
    "        train_idx_temp = np.array(train_index, dtype=\"int64\")\n",
    "        train_lab_temp = np.array(train_label, dtype=\"int64\")\n",
    "        state = np.random.get_state()\n",
    "        np.random.shuffle(train_idx_temp)\n",
    "        np.random.set_state(state)\n",
    "        np.random.shuffle(train_lab_temp)\n",
    "\n",
    "        label_idx=train_idx_temp[:int(label_rate*len(train_idx_temp))]\n",
    "        unlabel_idx=train_idx_temp[int(label_rate*len(train_idx_temp)):]\n",
    "        label=train_lab_temp[:int(label_rate*len(train_idx_temp))]\n",
    "        unlabel=train_lab_temp[int(label_rate*len(train_idx_temp)):]\n",
    "\n",
    "        feed_dict[\"node_index\"] = unlabel_idx\n",
    "        feed_dict[\"node_label\"] = unlabel\n",
    "        feed_dict['label_idx']= label_idx\n",
    "        feed_dict['label']= label\n",
    "    else:\n",
    "        feed_dict[\"node_label\"] = np.array(train_label, dtype=\"int64\")\n",
    "        feed_dict[\"node_index\"] = np.array(train_index, dtype=\"int64\")\n",
    "        \n",
    "\n",
    "    train_loss, train_acc = exe.run(train_program,\n",
    "                                feed=feed_dict,\n",
    "                                fetch_list=[loss, acc],\n",
    "                                return_numpy=True)\n",
    "\n",
    "    # Full Batch 验证\n",
    "    # 设定图上面那些节点要获取\n",
    "    # node_index: 训练节点的nid    \n",
    "    # node_label: 训练节点对应的标签\n",
    "    feed_dict[\"node_index\"] = np.array(val_index, dtype=\"int64\")\n",
    "    feed_dict[\"node_label\"] = np.array(val_label, dtype=\"int64\")\n",
    "    if use_label_e:\n",
    "        feed_dict['label_idx'] = np.array(train_index, dtype=\"int64\")\n",
    "        feed_dict['label'] = np.array(train_label, dtype=\"int64\")\n",
    "    val_loss, val_acc = exe.run(test_program,\n",
    "                            feed=feed_dict,\n",
    "                            fetch_list=[v_loss, v_acc],\n",
    "                            return_numpy=True)\n",
    "    print(\"Epoch\", epoch, \"Train Acc\", train_acc[0], \"Valid Acc\", val_acc[0])\n",
    "    if val_acc[0] > max_val_acc:\n",
    "        max_val_acc = val_acc[0]\n",
    "        fluid.io.save_persistables(exe, './output', train_program)\n",
    "\n",
    "    if val_acc_history <= val_acc[0]:\n",
    "        val_acc_history = val_acc[0]\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter > 150:\n",
    "            pass\n",
    "            #break\n",
    "    if  epoch == 1600 or epoch == 1800 or epoch == 1500 or epoch == 1300:\n",
    "        output(feed_dict, test_index,test_label, test_program, use_label_e, train_index, train_label, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （6）对测试集进行预测\n",
    "\n",
    "训练完成后，我们对测试集进行预测。预测的时候，由于不知道测试集合的标签，我们随意给一些测试label。最终我们获得测试数据的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "feed_dict[\"node_index\"] = np.array(test_index, dtype=\"int64\")\n",
    "feed_dict[\"node_label\"] = np.array(test_label, dtype=\"int64\") #假标签\n",
    "\n",
    "if use_label_e:\n",
    "    feed_dict['label_idx'] = np.array(train_index, dtype=\"int64\")\n",
    "    feed_dict['label'] = np.array(train_label, dtype=\"int64\")\n",
    "\n",
    "test_prediction = exe.run(test_program,\n",
    "                            feed=feed_dict,\n",
    "                            fetch_list=[v_pred],\n",
    "                            return_numpy=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （7）生成提交文件\n",
    "\n",
    "最后一步，我们可以使用pandas轻松生成提交文件，最后下载 submission.csv 提交就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data={\n",
    "                            \"nid\": test_index.reshape(-1),\n",
    "                            \"label\": test_prediction.reshape(-1)\n",
    "                        })\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他\n",
    "关于UniMP的理解，以及改进trick可参考我的两篇分享：\n",
    "\n",
    "[分享1](https://aistudio.baidu.com/aistudio/projectdetail/1650128)\n",
    "\n",
    "[分享2](https://aistudio.baidu.com/aistudio/projectdetail/1462003)\n",
    "\n",
    "## 赛题链接：[常规赛：图神经网络入门节点分类](https://aistudio.baidu.com/aistudio/competition/detail/59)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
